{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1711381334.929079  477423 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "Processing Videos: 100%|██████████| 50/50 [02:16<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import cv2\n",
    "import cvzone\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "####################################\n",
    "classID = 1  # 0 is fake and 1 is real\n",
    "outputFolderPath = 'DataCollect'\n",
    "confidence = 0.8\n",
    "save = True\n",
    "blurThreshold = 35  # Larger is more focus\n",
    "\n",
    "debug = False\n",
    "offsetPercentageW = 10\n",
    "offsetPercentageH = 20\n",
    "camWidth, camHeight = 640, 480\n",
    "floatingPoint = 6\n",
    "####################################\n",
    "\n",
    "# Directory setup (also adjust class label)\n",
    "videoDirectory = 'Dataset_real'\n",
    "videoFiles = [f for f in os.listdir(videoDirectory) if f.endswith('.mp4')]\n",
    "\n",
    "detector = FaceDetector()\n",
    "\n",
    "for videoFile in tqdm(videoFiles, desc=\"Processing Videos\"):\n",
    "    videoPath = os.path.join(videoDirectory, videoFile)\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    cap.set(3, camWidth)\n",
    "    cap.set(4, camHeight)\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break  # Exit loop if video ends or error occurs\n",
    "\n",
    "        imgOut = img.copy()\n",
    "        img, bboxs = detector.findFaces(img, draw=False)\n",
    "        listBlur = []  # True False values indicating if the faces are blur or not\n",
    "        listInfo = []  # The normalized values and the class name for the label txt file\n",
    "\n",
    "        if bboxs:\n",
    "            for bbox in bboxs:\n",
    "                x, y, w, h = bbox[\"bbox\"]\n",
    "                score = bbox[\"score\"][0]\n",
    "\n",
    "                if score > confidence:\n",
    "                    offsetW = (offsetPercentageW / 100) * w\n",
    "                    x = int(x - offsetW)\n",
    "                    w = int(w + offsetW * 2)\n",
    "                    offsetH = (offsetPercentageH / 100) * h\n",
    "                    y = int(y - offsetH * 3)\n",
    "                    h = int(h + offsetH * 3.5)\n",
    "\n",
    "                    if x < 0: x = 0\n",
    "                    if y < 0: y = 0\n",
    "                    if w < 0: w = 0\n",
    "                    if h < 0: h = 0\n",
    "\n",
    "                    imgFace = img[y:y + h, x:x + w]\n",
    "                    if debug:\n",
    "                        cv2.imshow(\"Face\", imgFace)\n",
    "                    blurValue = int(cv2.Laplacian(imgFace, cv2.CV_64F).var())\n",
    "                    listBlur.append(blurValue > blurThreshold)\n",
    "\n",
    "                    ih, iw, _ = img.shape\n",
    "                    xc, yc = x + w / 2, y + h / 2\n",
    "                    xcn, ycn = round(xc / iw, floatingPoint), round(yc / ih, floatingPoint)\n",
    "                    wn, hn = round(w / iw, floatingPoint), round(h / ih, floatingPoint)\n",
    "\n",
    "                    if xcn > 1: xcn = 1\n",
    "                    if ycn > 1: ycn = 1\n",
    "                    if wn > 1: wn = 1\n",
    "                    if hn > 1: hn = 1\n",
    "\n",
    "                    listInfo.append(f\"{classID} {xcn} {ycn} {wn} {hn}\\n\")\n",
    "\n",
    "                    cv2.rectangle(imgOut, (x, y, w, h), (255, 0, 0), 3)\n",
    "                    cvzone.putTextRect(imgOut, f'Score: {int(score * 100)}% Blur: {blurValue}', (x, y - 0), scale=2, thickness=3)\n",
    "                    if debug:\n",
    "                        cv2.rectangle(img, (x, y, w, h), (255, 0, 0), 3)\n",
    "                        cvzone.putTextRect(img, f'Score: {int(score * 100)}% Blur: {blurValue}', (x, y - 0), scale=2, thickness=3)\n",
    "\n",
    "            if save and all(listBlur) and listBlur:\n",
    "                timeNow = time()\n",
    "                timeNow = str(timeNow).split('.')\n",
    "                timeNow = timeNow[0] + timeNow[1]\n",
    "                cv2.imwrite(f\"{outputFolderPath}/{timeNow}.jpg\", img)\n",
    "                for info in listInfo:\n",
    "                    with open(f\"{outputFolderPath}/{timeNow}.txt\", 'a') as f:\n",
    "                        f.write(info)\n",
    "\n",
    "        if debug:\n",
    "            cv2.imshow(\"Image\", imgOut)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
